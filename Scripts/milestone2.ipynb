{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Enable FastF1 caching to avoid repeated API calls\n",
    "fastf1.Cache.enable_cache('f1_cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MILESTONE 2: Feature Engineering, Feature Selection, and Data Modeling\n",
    "\n",
    "## 1. Data Collection Using FastF1\n",
    "# Let's collect data from the 2023 season for training\n",
    "def collect_race_data(year=2023, race_types=None):\n",
    "    \"\"\"\n",
    "    Collect race data for a specific year\n",
    "    \n",
    "    Parameters:\n",
    "    year - The F1 season year\n",
    "    race_types - Types of sessions to collect (e.g., 'R' for Race, 'Q' for Qualifying)\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with combined race data\n",
    "    \"\"\"\n",
    "    if race_types is None:\n",
    "        race_types = ['R']  # Default to Race sessions\n",
    "    \n",
    "    all_data = []\n",
    "    # Get all events for the year\n",
    "    events = fastf1.get_event_schedule(year)\n",
    "    \n",
    "    for _, event in tqdm(events.iterrows(), desc=f\"Processing {year} events\", total=len(events)):\n",
    "        for session_type in race_types:\n",
    "            try:\n",
    "                # Load session\n",
    "                session = fastf1.get_session(year, event['EventName'], session_type)\n",
    "                session.load(laps=True, telemetry=True, weather=True)\n",
    "                \n",
    "                # Get lap data\n",
    "                laps_data = session.laps.copy()\n",
    "                \n",
    "                # Add event info\n",
    "                laps_data['EventName'] = event['EventName']\n",
    "                laps_data['CircuitName'] = event['OfficialEventName']\n",
    "                laps_data['Year'] = year\n",
    "                \n",
    "                all_data.append(laps_data)\n",
    "                print(f\"Added data for {event['EventName']} - {session_type}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {event['EventName']} - {session_type}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"No data collected\")\n",
    "        return None\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    return combined_data\n",
    "\n",
    "# Collect Race and Qualifying data\n",
    "print(\"Collecting 2023 race data...\")\n",
    "race_data_2023 = collect_race_data(year=2023, race_types=['R'])\n",
    "qualifying_data_2023 = collect_race_data(year=2023, race_types=['Q'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Collect 2022 data for additional training\n",
    "# race_data_2022 = collect_race_data(year=2022, race_types=['R'])\n",
    "# qualifying_data_2022 = collect_race_data(year=2022, race_types=['Q'])\n",
    "\n",
    "## 2. Feature Engineering\n",
    "\n",
    "def engineer_features(race_data, qualifying_data=None):\n",
    "    \"\"\"\n",
    "    Engineer features from race and qualifying data\n",
    "    \n",
    "    Parameters:\n",
    "    race_data - Race session lap data\n",
    "    qualifying_data - Qualifying session lap data (optional)\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    # 2.1 Create driver performance metrics\n",
    "    # Calculate average lap time per driver per race\n",
    "    race_features = race_data.copy()\n",
    "    \n",
    "    # Filter out outlier laps\n",
    "    race_features = race_features[\n",
    "        (race_features['IsPersonalBest'] == True) |\n",
    "        (~race_features['LapTime'].isna())\n",
    "    ]\n",
    "    \n",
    "    # Convert time deltas to seconds for easier manipulation\n",
    "    for col in ['LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time']:\n",
    "        if col in race_features.columns:\n",
    "            race_features[f'{col}_seconds'] = race_features[col].dt.total_seconds()\n",
    "    \n",
    "    # 2.2 Driver Consistency Features\n",
    "    # Calculate standard deviation of lap times per driver per race\n",
    "    driver_consistency = race_features.groupby(['Year', 'EventName', 'Driver'])[\n",
    "        'LapTime_seconds'\n",
    "    ].agg(['mean', 'std', 'count']).reset_index()\n",
    "    \n",
    "    driver_consistency.columns = [\n",
    "        'Year', 'EventName', 'Driver', 'AvgLapTime', 'LapTimeStd', 'LapCount'\n",
    "    ]\n",
    "    \n",
    "    # 2.3 Sector Performance Features - FIX: Use a list instead of tuple for column selection\n",
    "    # Check if all sector columns exist\n",
    "    sector_columns = []\n",
    "    for col in ['Sector1Time_seconds', 'Sector2Time_seconds', 'Sector3Time_seconds']:\n",
    "        if col in race_features.columns:\n",
    "            sector_columns.append(col)\n",
    "    \n",
    "    # Only proceed if we have sector data\n",
    "    if sector_columns:\n",
    "        sector_performance = race_features.groupby(['Year', 'EventName', 'Driver'])[\n",
    "            sector_columns  # Use list of columns that exist\n",
    "        ].agg(['mean', 'std']).reset_index()\n",
    "        \n",
    "        # Flatten the multi-level columns\n",
    "        sector_performance.columns = [\n",
    "            '_'.join(col).strip('_') if isinstance(col, tuple) else col \n",
    "            for col in sector_performance.columns.values\n",
    "        ]\n",
    "    else:\n",
    "        # Create empty DataFrame with correct columns if sector data not available\n",
    "        sector_performance = pd.DataFrame(columns=['Year', 'EventName', 'Driver'])\n",
    "    \n",
    "    # 2.4 Qualifying Performance (if available)\n",
    "    qualifying_features = None\n",
    "    if qualifying_data is not None:\n",
    "        qualifying_features = qualifying_data.copy()\n",
    "        \n",
    "        # Get fastest qualifying lap per driver per race\n",
    "        qualifying_best = qualifying_features.groupby(['Year', 'EventName', 'Driver']).agg({\n",
    "            'LapTime': 'min'\n",
    "        }).reset_index()\n",
    "        \n",
    "        qualifying_best['QualifyingTime_seconds'] = qualifying_best['LapTime'].dt.total_seconds()\n",
    "    \n",
    "    # 2.5 Speed Features - check if speed columns exist\n",
    "    speed_columns = []\n",
    "    for col in ['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']:\n",
    "        if col in race_features.columns:\n",
    "            speed_columns.append(col)\n",
    "    \n",
    "    if speed_columns:\n",
    "        speed_features = race_features.groupby(['Year', 'EventName', 'Driver'])[\n",
    "            speed_columns\n",
    "        ].agg(['mean', 'max']).reset_index()\n",
    "        \n",
    "        # Flatten the multi-level columns\n",
    "        speed_features.columns = [\n",
    "            '_'.join(col).strip('_') if isinstance(col, tuple) else col \n",
    "            for col in speed_features.columns.values\n",
    "        ]\n",
    "    else:\n",
    "        # Create empty DataFrame with correct columns if speed data not available\n",
    "        speed_features = pd.DataFrame(columns=['Year', 'EventName', 'Driver'])\n",
    "    \n",
    "    # 2.6 Tire Strategy Features - check if Compound column exists\n",
    "    if 'Compound' in race_features.columns:\n",
    "        tire_features = race_features.groupby(['Year', 'EventName', 'Driver', 'Compound'])[\n",
    "            'LapTime_seconds'\n",
    "        ].count().reset_index()\n",
    "        \n",
    "        tire_pivot = tire_features.pivot_table(\n",
    "            index=['Year', 'EventName', 'Driver'],\n",
    "            columns='Compound',\n",
    "            values='LapTime_seconds',\n",
    "            fill_value=0\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        # Create empty DataFrame with correct columns if compound data not available\n",
    "        tire_pivot = pd.DataFrame(columns=['Year', 'EventName', 'Driver'])\n",
    "    \n",
    "    # 2.7 Grid Position and Position Change - check if position columns exist\n",
    "    position_columns = {'GridPosition': 'first'}\n",
    "    if 'Position' in race_features.columns:\n",
    "        position_columns['Position'] = ['first', 'last']\n",
    "    \n",
    "    position_features = race_features.groupby(['Year', 'EventName', 'Driver']).agg(\n",
    "        position_columns\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Flatten the multi-level columns if they exist\n",
    "    if 'Position' in position_columns:\n",
    "        position_features.columns = [\n",
    "            '_'.join(col).strip('_') if isinstance(col, tuple) else col \n",
    "            for col in position_features.columns.values\n",
    "        ]\n",
    "        \n",
    "        # Calculate position change if both grid and final position are available\n",
    "        if 'GridPosition' in position_features.columns and 'Position_last' in position_features.columns:\n",
    "            position_features['PositionChange'] = position_features['GridPosition'] - position_features['Position_last']\n",
    "    \n",
    "    # 2.9 Combine all features - start with driver consistency as base\n",
    "    combined_features = driver_consistency.copy()\n",
    "    \n",
    "    # Function to safely merge DataFrames\n",
    "    def safe_merge(left, right, on_cols, how='left'):\n",
    "        # Only merge if right DataFrame is not empty\n",
    "        if not right.empty and all(col in right.columns for col in on_cols):\n",
    "            return pd.merge(left, right, on=on_cols, how=how)\n",
    "        return left\n",
    "    \n",
    "    # Merge sector performance if available\n",
    "    combined_features = safe_merge(\n",
    "        combined_features,\n",
    "        sector_performance,\n",
    "        on=['Year', 'EventName', 'Driver']\n",
    "    )\n",
    "    \n",
    "    # Merge speed features if available\n",
    "    combined_features = safe_merge(\n",
    "        combined_features,\n",
    "        speed_features,\n",
    "        on=['Year', 'EventName', 'Driver']\n",
    "    )\n",
    "    \n",
    "    # Merge tire features if available\n",
    "    combined_features = safe_merge(\n",
    "        combined_features,\n",
    "        tire_pivot,\n",
    "        on=['Year', 'EventName', 'Driver']\n",
    "    )\n",
    "    \n",
    "    # Merge position features if available\n",
    "    combined_features = safe_merge(\n",
    "        combined_features,\n",
    "        position_features,\n",
    "        on=['Year', 'EventName', 'Driver']\n",
    "    )\n",
    "    \n",
    "    # Merge qualifying features if available\n",
    "    if qualifying_features is not None:\n",
    "        qualifying_best = qualifying_best[['Year', 'EventName', 'Driver', 'QualifyingTime_seconds']]\n",
    "        combined_features = safe_merge(\n",
    "            combined_features,\n",
    "            qualifying_best,\n",
    "            on=['Year', 'EventName', 'Driver']\n",
    "        )\n",
    "    \n",
    "    # Fill missing values with median to avoid NaNs\n",
    "    numeric_cols = combined_features.select_dtypes(include=['number']).columns\n",
    "    combined_features[numeric_cols] = combined_features[numeric_cols].fillna(\n",
    "        combined_features[numeric_cols].median()\n",
    "    )\n",
    "    \n",
    "    return combined_features\n",
    "# Engineer features from collected data\n",
    "print(\"Engineering features...\")\n",
    "features_df = engineer_features(race_data_2023, qualifying_data_2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 3. Feature Selection\n",
    "\n",
    "def select_features(features_df, target_col='AvgLapTime', test_size=0.2):\n",
    "    \"\"\"\n",
    "    Select relevant features using feature importance\n",
    "    \n",
    "    Parameters:\n",
    "    features_df - DataFrame with all engineered features\n",
    "    target_col - Target column for prediction\n",
    "    test_size - Test set size for train-test split\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with selected features and train-test split data\n",
    "    \"\"\"\n",
    "    # Drop non-feature columns for modeling\n",
    "    non_feature_cols = ['Year', 'EventName', 'Driver']\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = features_df.drop(non_feature_cols + [target_col], axis=1)\n",
    "    y = features_df[target_col]\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape[0]}\")\n",
    "    print(f\"Test set size: {X_test.shape[0]}\")\n",
    "    \n",
    "    # Use Random Forest to evaluate feature importance\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 10 most important features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "    plt.title('Feature Importance (Random Forest)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Select top features (80% of cumulative importance)\n",
    "    cum_importance = feature_importance['Importance'].cumsum()\n",
    "    top_features = feature_importance[cum_importance <= 0.8]['Feature'].tolist()\n",
    "    \n",
    "    if not top_features:  # If no features have cumulative importance <= 0.8\n",
    "        top_features = feature_importance['Feature'].head(10).tolist()\n",
    "    \n",
    "    print(f\"Selected {len(top_features)} features with 80% cumulative importance\")\n",
    "    \n",
    "    # Filter features\n",
    "    X_train_selected = X_train[top_features]\n",
    "    X_test_selected = X_test[top_features]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "    X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train_scaled,\n",
    "        'X_test': X_test_scaled,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'feature_names': top_features,\n",
    "        'feature_importance': feature_importance,\n",
    "        'scaler': scaler\n",
    "    }\n",
    "\n",
    "# Select features\n",
    "print(\"Selecting features...\")\n",
    "selected_features = select_features(features_df, target_col='AvgLapTime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 4. Data Modeling\n",
    "\n",
    "def train_models(selected_features):\n",
    "    \"\"\"\n",
    "    Train multiple regression models and evaluate performance\n",
    "    \n",
    "    Parameters:\n",
    "    selected_features - Dictionary with selected features and train-test data\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with trained models and performance metrics\n",
    "    \"\"\"\n",
    "    X_train = selected_features['X_train']\n",
    "    X_test = selected_features['X_test']\n",
    "    y_train = selected_features['y_train']\n",
    "    y_test = selected_features['y_test']\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results = []\n",
    "    trained_models = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{name} Performance:\")\n",
    "        print(f\"MAE: {mae:.4f} seconds\")\n",
    "        print(f\"RMSE: {rmse:.4f} seconds\")\n",
    "        print(f\"R²: {r2:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        results.append({\n",
    "            'model': name,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2\n",
    "        })\n",
    "        \n",
    "        trained_models[name] = model\n",
    "    \n",
    "    # Convert to DataFrame for comparison\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Visualize model comparison\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(x='model', y='mae', data=results_df)\n",
    "    plt.title('Model Comparison - MAE (lower is better)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Mean Absolute Error (seconds)')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.barplot(x='model', y='r2', data=results_df)\n",
    "    plt.title('Model Comparison - R² (higher is better)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('R² Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name = results_df.loc[results_df['mae'].idxmin(), 'model']\n",
    "    print(f\"Best model based on MAE: {best_model_name}\")\n",
    "    \n",
    "    return {\n",
    "        'trained_models': trained_models,\n",
    "        'results': results_df,\n",
    "        'best_model_name': best_model_name\n",
    "    }\n",
    "\n",
    "# Train models\n",
    "print(\"Training models...\")\n",
    "model_results = train_models(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 5. Race Prediction Implementation\n",
    "\n",
    "def predict_race_results(qualifying_data, model, feature_names, scaler):\n",
    "    \"\"\"\n",
    "    Predict race results using qualifying data\n",
    "    \n",
    "    Parameters:\n",
    "    qualifying_data - Qualifying data for the race\n",
    "    model - Trained prediction model\n",
    "    feature_names - Names of features used by the model\n",
    "    scaler - Fitted scaler for the model\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with predicted race results\n",
    "    \"\"\"\n",
    "    # Prepare features from qualifying data\n",
    "    # This would need to be adapted based on available data\n",
    "    X_pred = qualifying_data[feature_names].copy()\n",
    "    \n",
    "    # Scale features\n",
    "    X_pred_scaled = scaler.transform(X_pred)\n",
    "    \n",
    "    # Make predictions\n",
    "    predicted_times = model.predict(X_pred_scaled)\n",
    "    \n",
    "    # Add predictions to qualifying data\n",
    "    results = qualifying_data.copy()\n",
    "    results['PredictedRaceTime'] = predicted_times\n",
    "    \n",
    "    # Sort by predicted race time (faster times first)\n",
    "    results = results.sort_values('PredictedRaceTime').reset_index(drop=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Prepare data for the next race prediction\n",
    "# In a real-world scenario, you would need to collect actual qualifying data\n",
    "# for the upcoming race and engineer the same features\n",
    "\n",
    "# For demonstration, let's create a dummy qualifying dataset\n",
    "print(\"Creating sample prediction for a future race...\")\n",
    "next_race_qualifying = features_df.copy()\n",
    "\n",
    "# Select the best model\n",
    "best_model = model_results['trained_models'][model_results['best_model_name']]\n",
    "\n",
    "# Predict race results\n",
    "predicted_results = predict_race_results(\n",
    "    next_race_qualifying,\n",
    "    best_model,\n",
    "    selected_features['feature_names'],\n",
    "    selected_features['scaler']\n",
    ")\n",
    "\n",
    "# Show predicted race results\n",
    "print(\"\\nPredicted Race Results:\")\n",
    "print(predicted_results[['Driver', 'PredictedRaceTime']].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Deliverables Summary\n",
    "\n",
    "# 6.1 Selected Features with Justification\n",
    "print(\"\\nSelected Features with Justification:\")\n",
    "top_features = selected_features['feature_importance']\n",
    "for feature, importance in zip(top_features['Feature'].head(10), top_features['Importance'].head(10)):\n",
    "    print(f\"- {feature}: Importance score = {importance:.4f}\")\n",
    "\n",
    "# 6.2 Model Performance Summary\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(model_results['results'].sort_values('mae'))\n",
    "\n",
    "# 6.3 Best Model Analysis\n",
    "print(f\"\\nBest Model: {model_results['best_model_name']}\")\n",
    "best_model_performance = model_results['results'][model_results['results']['model'] == model_results['best_model_name']]\n",
    "print(f\"MAE: {best_model_performance['mae'].values[0]:.4f} seconds\")\n",
    "print(f\"RMSE: {best_model_performance['rmse'].values[0]:.4f} seconds\")\n",
    "print(f\"R²: {best_model_performance['r2'].values[0]:.4f}\")\n",
    "\n",
    "# 6.4 Conclusions and Next Steps\n",
    "print(\"\\nConclusions:\")\n",
    "print(\"1. The most important features for predicting F1 lap times are:\")\n",
    "for i, (feature, importance) in enumerate(zip(top_features['Feature'].head(3), top_features['Importance'].head(3))):\n",
    "    print(f\"   {i+1}. {feature} (Importance: {importance:.4f})\")\n",
    "\n",
    "print(f\"\\n2. The {model_results['best_model_name']} model performed best with MAE of {best_model_performance['mae'].values[0]:.4f} seconds\")\n",
    "\n",
    "print(\"\\n3. Next steps for further improvement:\")\n",
    "print(\"   - Collect more historical data (e.g., from 2021 and 2022)\")\n",
    "print(\"   - Incorporate additional telemetry data for more detailed driver performance metrics\")\n",
    "print(\"   - Add weather forecast data for future race predictions\")\n",
    "print(\"   - Implement hyperparameter tuning for model optimization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
